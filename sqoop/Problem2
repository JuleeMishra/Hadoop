********************************************************************************************************************
part_1: 
**************************************************************************************************************
[cloudera@quickstart ~]$ sqoop import \
> --connect jdbc:mysql://localhost/retail_db \
> --username root \
> --password cloudera \
> --table products \
> --as-textfile \
> --target-dir /user/cloudera/products \
> --fields-terminated-by '|';

********************************************************************************************************************
part_2: 
**************************************************************************************************************
[cloudera@quickstart ~]$ hadoop fs -mkdir /user/cloudera/problem2
[cloudera@quickstart ~]$ hadoop fs -mv /user/cloudera/products /user/cloudera/problem2
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/problem2

********************************************************************************************************************
part_3: 
**************************************************************************************************************
[cloudera@quickstart ~]$ hadoop fs -chmod 765  /user/cloudera/problem2/products/*
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/problem2/products/
Found 5 items
-rwxrw-r-x   1 cloudera cloudera          0 2018-03-28 20:07 /user/cloudera/problem2/products/_SUCCESS
-rwxrw-r-x   1 cloudera cloudera      41419 2018-03-28 20:07 /user/cloudera/problem2/products/part-m-00000
-rwxrw-r-x   1 cloudera cloudera      43660 2018-03-28 20:07 /user/cloudera/problem2/products/part-m-00001
-rwxrw-r-x   1 cloudera cloudera      42195 2018-03-28 20:07 /user/cloudera/problem2/products/part-m-00002
-rwxrw-r-x   1 cloudera cloudera      46719 2018-03-28 20:07 /user/cloudera/problem2/products/part-m-00003

total 3 combination of letters are there with an extra "-" before.
1st rwx combination - owner
2nd rwx combination - group
3rd rwx combination - others
change of permission:

0 --> No Permission      --> ---
1 --> exec Permission    --> --x
2 --> write Permission   --> -w-
3 --> write & Exec       --> -wx
4 --> read Permission    --> r-- 
5 --> read & Exec        --> r-x
6 --> read & write       --> rw- 
7 --> read, write & Exec --> rwx  

********************************************************************************************************************
part_4: 
**************************************************************************************************************
USING DF API:

scala> val productsDF = sc.textFile("/user/cloudera/problem2/products").map(x => (x.split('|')(0),x.split('|')(1),x.split('|')(2),x.split('|')(3),x.split('|')(4),x.split('|')(5))).toDF("product_id","product_category_id","product_name","product_description","product_price","product_image")


scala> val DFResult = productsDF.filter("product_price < 100").groupBy("product_category_id").agg(max("product_price").alias("Max_price"),countDistinct(col("productID")).alias("Total_product"),round(avg("product_price"),2).alias("Avg_Price"),min("product_price").alias("Min_price"));
filteredProduct: org.apache.spark.sql.DataFrame = [product_category_id: string, Max_price: string, Total_product: bigint, Avg_Price: double, Min_price: string]

scala> DFResult.show()
+-------------------+---------+-------------+---------+---------+               
|product_category_id|Max_price|Total_product|Avg_Price|Min_price|
+-------------------+---------+-------------+---------+---------+
|                 50|     60.0|           14|    53.71|     34.0|
|                 51|    79.97|           10|    40.99|     28.0|
|                 52|     65.0|           19|    28.74|     10.0|
|                 53|    99.99|            8|    91.24|    69.99|
|                 54|    99.99|           18|    61.43|    34.99|
|                 55|     9.99|           24|     31.5|     18.0|
|                 56|     90.0|           22|     60.5|     25.0|
|                 57|    99.99|           18|    59.16|      0.0|
|                 58|     60.0|           13|    43.69|     22.0|
|                 59|     70.0|           10|     38.6|     28.0|
|                  2|    99.99|           11|    66.81|    29.97|
|                  3|     99.0|           19|    55.73|      0.0|
|                  4|    99.95|           10|    55.89|    21.99|
|                  5|    99.99|           13|    57.99|     14.0|
|                  6|    99.99|           19|    43.94|     14.0|
|                  7|    99.98|           18|    47.49|     14.0|
|                  8|    99.98|           19|    41.67|    21.99|
|                  9|    99.99|           17|    67.17|     28.0|
|                 10|    99.95|            4|    78.48|    34.99|
|                 11|    99.99|            5|    76.99|    34.99|
+-------------------+---------+-------------+---------+---------+
only showing top 20 rows

5b)
USING Spark-SQL API:
scala> val DFResult = productsDF.filter("product_price < 100").groupBy("product_category_id").agg(max("product_price").alias("Max_price"),count("product_name").alias("Total_product"),round(avg("product_price"),2).alias("Avg_Price"),min("product_price").alias("Min_price"));
DFResult: org.apache.spark.sql.DataFrame = [product_category_id: string, Max_price: string, Total_product: bigint, Avg_Price: double, Min_price: string]

scala> productsDF.registerTempTable("products")

scala> val sparkSqlResults = sqlContext.sql("select product_category_id, max(product_price) Max_price, "+
            "count(product_name) total_products, "+
            "avg(product_price) avg_price, "+
            "min(product_price) min_price "+
            "from products "+
            "where product_price < 100 "+
            "group by product_category_id "
            )
sparkSqlResults: org.apache.spark.sql.DataFrame = [Max_price: string, total_products: bigint, avg_price: double, min_price: string]
scala> sparkSqlResults.show()
+-------------------+---------+--------------+------------------+---------+     
|product_category_id|Max_price|total_products|         avg_price|min_price|
+-------------------+---------+--------------+------------------+---------+
|                 50|     60.0|            14|53.714285714285715|     34.0|
|                 51|    79.97|            10| 40.99300000000001|     28.0|
|                 52|     65.0|            19|28.736315789473686|     10.0|
|                 53|    99.99|             8|             91.24|    69.99|
|                 54|    99.99|            18| 61.43444444444444|    34.99|
|                 55|     9.99|            24|31.498333333333335|     18.0|
|                 56|     90.0|            22| 60.49818181818182|     25.0|
|                 57|    99.99|            18|59.160000000000004|      0.0|
|                 58|     60.0|            13| 43.69230769230769|     22.0|
|                 59|     70.0|            10|            38.597|     28.0|
|                  2|    99.99|            11| 66.80636363636364|    29.97|
|                  3|     99.0|            19|55.730000000000004|      0.0|
|                  4|    99.95|            10|            55.887|    21.99|
|                  5|    99.99|            13| 57.98923076923077|     14.0|
|                  6|    99.99|            19| 43.93631578947369|     14.0|
|                  7|    99.98|            18|47.488888888888894|     14.0|
|                  8|    99.98|            19|41.673157894736846|    21.99|
|                  9|    99.99|            17| 67.16882352941177|     28.0|
|                 10|    99.95|             4|           78.4825|    34.99|
|                 11|    99.99|             5|             76.99|    34.99|
+-------------------+---------+--------------+------------------+---------+
only showing top 20 rows


5c)
USING RDD API:
scala> val productsDF = sc.textFile("/user/cloudera/problem2/products").map(x => (x.split('|')(0),x.split('|')(1),x.split('|')(2),x.split('|')(3),x.split('|')(4),x.split('|')(5))).toDF
productsDF: org.apache.spark.sql.DataFrame = [_1: string, _2: string, _3: string, _4: string, _5: string, _6: string]

scala> val productsRDD = productsDF.map(x => {
      (x(1).toString.toInt, x(4).toString.toDouble)
      }).take(5).foreach(println)
(2,59.98)   		 //(product_cat_id, product_price)---->(k,v)
(2,129.99)
(2,89.99)
(2,89.99)
(2,199.99)

scala> val productResult = productsRDD.aggregateByKey((0.0, 0.0, 0, 9999999999999.0))(  ---> initialization always based on the required output.
     |       (x,y) => (math.max(x._1, y), x._2+y, x._3+1, math.min(x._4,y)),  ---> x is the initialized tuple, y is the value part of RDD.
     |       (x,y) => (math.max(x._1,y._1),(x._2+y._2),x._3+y._3,math.min(x._4,y._4)) //(product_cat_id, (max_price, total_price, product_count, min_price))
     |       )
productResult: org.apache.spark.rdd.RDD[(Int, (Double, Int, Double, Double))] = ShuffledRDD[17] at aggregateByKey at <console>:31

scala> productResult.collect.foreach(println)
(52,(170.0,24,1355.99,10.0))
(56,(159.99,24,1650.94,9.99))
(4,(1799.99,24,6248.65,21.99))

scala> val productResult1 = productResult.map(x => (x._1, x._2._1, x._2._2, x._2._3, x._2._4))
productResult1: org.apache.spark.rdd.RDD[(Int, Double, Int, Double, Double)] = MapPartitionsRDD[20] at map at <console>:33
(52,170.0,24,1355.99,10.0)
(56,159.99,24,1650.94,9.99)
(4,1799.99,24,6248.65,21.99)
(16,349.99,24,2834.7599999999984,27.99)
(48,799.99,24,6849.709999999997,19.98)



mysql> select * from products limit 10;
+------------+---------------------+-----------------------------------------------+---------------------+---------------+-----------------------------------------------------------------------------------------+
| product_id | product_category_id | product_name                                  | product_description | product_price | product_image                                                                           |
+------------+---------------------+-----------------------------------------------+---------------------+---------------+-----------------------------------------------------------------------------------------+
|          1 |                   2 | Quest Q64 10 FT. x 10 FT. Slant Leg Instant U |                     |         59.98 | http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy   |
|          2 |                   2 | Under Armour Men's Highlight MC Football Clea |                     |        129.99 | http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat        |
|          3 |                   2 | Under Armour Men's Renegade D Mid Football Cl |                     |         89.99 | http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat      |
|          4 |                   2 | Under Armour Men's Renegade D Mid Football Cl |                     |         89.99 | http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat      |
|          5 |                   2 | Riddell Youth Revolution Speed Custom Footbal |                     |        199.99 | http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet   |
|          6 |                   2 | Jordan Men's VI Retro TD Football Cleat       |                     |        134.99 | http://images.acmesports.sports/Jordan+Men%27s+VI+Retro+TD+Football+Cleat               |
|          7 |                   2 | Schutt Youth Recruit Hybrid Custom Football H |                     |         99.99 | http://images.acmesports.sports/Schutt+Youth+Recruit+Hybrid+Custom+Football+Helmet+2014 |
|          8 |                   2 | Nike Men's Vapor Carbon Elite TD Football Cle |                     |        129.99 | http://images.acmesports.sports/Nike+Men%27s+Vapor+Carbon+Elite+TD+Football+Cleat       |
|          9 |                   2 | Nike Adult Vapor Jet 3.0 Receiver Gloves      |                     |            50 | http://images.acmesports.sports/Nike+Adult+Vapor+Jet+3.0+Receiver+Gloves                |
|         10 |                   2 | Under Armour Men's Highlight MC Football Clea |                     |        129.99 | http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat        |
+------------+---------------------+-----------------------------------------------+---------------------+---------------+-----------------------------------------------------------------------------------------+
10 rows in set (0.02 sec)







